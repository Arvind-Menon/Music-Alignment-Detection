{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audio_Emotion_Classifier_Inception_V1_2ndAUX_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boVB5xMD8F1n",
        "colab_type": "text"
      },
      "source": [
        "# Acknowledgement\n",
        "### This Notebook has been realised owing to the tutorial series by Valerio Velardo. The playlist can be found at https://www.youtube.com/channel/UCZPFjMe1uRSirmSpznqvJfQ/playlists under the title \"Deep Learning (for Audio) with python. His tutorial involved genre-classification among 10 classes. \n",
        "I modified his work for my mood-classification among 4 classes task. However, the deep learning architecture used was not influenced by his tutorial. His main influence has been in user defined functions for saving and loading data with preprocessing the data, and ploting the history curve. Valerio has been made aware of me using his tutorial for my project through LinkedIn. He even undertook my survey and had like a post regarding my project on LinkedIn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7Uoh4mSlud-",
        "colab_type": "text"
      },
      "source": [
        "# Load Google Drive(s)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC8W8MUzwqkf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "705de0b7-9766-4ae4-b2de-c321296c2fe9"
      },
      "source": [
        "## Use the account \n",
        "## Email: arvind.final.dissertation@gmail.com\n",
        "## Password: final paper\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5Rj--1JwqTb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "a803f62f-ad8a-4534-a8c3-7813c7ceffea"
      },
      "source": [
        "### To invoke a 2nd google drive in colab\n",
        "\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "!sudo mkdir /content/drive1\n",
        "!google-drive-ocamlfuse /content/drive1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 144579 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.22-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.22-0ubuntu3~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.22-0ubuntu3~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOCgp_Ral4NQ",
        "colab_type": "text"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSG4UeQvUJ_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras as keras\n",
        "import matplotlib.pyplot as plot\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from keras.layers import Conv2D, MaxPooling2D, Input, AveragePooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.regularizers import l2\n",
        "\n",
        "#Sci-kit learn libs\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Env7h4DkmArR",
        "colab_type": "text"
      },
      "source": [
        "# User Defined Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wai8d0LXUxle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def json_load(json_path):\n",
        "    \"\"\"Loads the pre-processessed json file.\n",
        "\n",
        "        json_path: Path to json file containing data\n",
        "        X : MFFC array\n",
        "        y : encoded labels\n",
        "        mapping: corresponding labels\n",
        "    \"\"\"\n",
        "\n",
        "    with open(json_path, \"r\") as fp:\n",
        "        data = json.load(fp)\n",
        "\n",
        "    X = np.array(data[\"mfcc\"])\n",
        "    y = np.array(data[\"labels\"])\n",
        "    mapping = data[\"mapping\"]\n",
        "    return X, y, mapping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4tjuEoAU0Tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def viz_history(history):\n",
        "    \"\"\"Plots accuracy-vs-epoch and error-vs-epoch plots with \n",
        "\n",
        "        :param history: Training history of model\n",
        "        :return:\n",
        "    \"\"\"\n",
        "\n",
        "    figure, axes = plot.subplots(figsize=(10,4), nrows=1, ncols=2)\n",
        "    figure.tight_layout(pad=3.0)\n",
        "    \n",
        "    axes[0].set_xlabel(\"Epoch\")\n",
        "    axes[1].set_xlabel(\"Epoch\")\n",
        "\n",
        "    # create accuracy sublpot\n",
        "    axes[0].plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
        "    axes[0].plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
        "    axes[0].set_ylabel(\"Accuracy\")\n",
        "    axes[0].legend(loc=\"upper right\")\n",
        "    axes[0].set_title(\"Accuracy-vs-Epoch\")\n",
        "\n",
        "    # create error sublpot\n",
        "    axes[1].plot(history.history[\"loss\"], label=\"Train Error\")\n",
        "    axes[1].plot(history.history[\"val_loss\"], label=\"Validation Error\")\n",
        "    axes[1].set_ylabel(\"Error\")    \n",
        "    axes[1].legend(loc=\"upper right\")\n",
        "    axes[1].set_title(\"error-vs-epoch\")\n",
        "\n",
        "    plot.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6zMeetmU4mW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_val_test(validation_split, test_split):\n",
        "    \"\"\"Loads data and splits it into train, validation and test sets.\n",
        "\n",
        "        In AER splits, Validation_split of 0.1 and test_split of 0.1 is used ----> train:0.8,val:0.09,test:0.1\n",
        "        The above split produced the highest accuracies\n",
        "    \"\"\"\n",
        "\n",
        "    # load data\n",
        "    X, y, mapping = json_load(JSON_PATH)\n",
        "\n",
        "    # create train, validation and test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_split, random_state=42, stratify = y)\n",
        "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_split, random_state=42, stratify = y_train)\n",
        "\n",
        "    # add an axis to input sets\n",
        "    X_train = X_train[..., np.newaxis]\n",
        "    X_validation = X_validation[..., np.newaxis]\n",
        "    X_test = X_test[..., np.newaxis]\n",
        "\n",
        "    return X_train, X_validation, X_test, y_train, y_validation, y_test, mapping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNbyIHixgqQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def inception_layer(input_incpetion):  \n",
        "    # \"\"\"Returns the output of the inception module\n",
        "\n",
        "    #     :param input_inception: The inception modules input\n",
        "    #     :retun output_inception: Output of the inception module\n",
        "\n",
        "    #     The below code has been adapted from a tutorial by Maël Fabian at: https://maelfabien.github.io/deeplearning/inception/#\n",
        "    # \"\"\"\n",
        "\n",
        "    # Regularization penalty\n",
        "      reg = 0.00001\n",
        "\n",
        "      # 1st Arm\n",
        "      inception1 = Conv2D(96, (1,1), padding='same', activation='relu', bias_regularizer= l2(reg), kernel_regularizer=l2(reg))(input_incpetion)\n",
        "      inception1 = Conv2D(128, (3,3), padding='same', activation='relu', bias_regularizer= l2(reg), kernel_regularizer=l2(reg))(inception1)\n",
        "\n",
        "      # 2nd Arm\n",
        "      inception2 = Conv2D(16, (1,1), padding='same', activation='relu', bias_regularizer= l2(reg), kernel_regularizer=l2(reg))(input_incpetion)\n",
        "      inception2 = Conv2D(32, (5,5), padding='same', activation='relu', bias_regularizer= l2(reg), kernel_regularizer=l2(reg))(inception2)\n",
        "     \n",
        "      # 3rd Arm\n",
        "      inception3 = MaxPooling2D((3,3), strides=(1,1), padding='same')(input_incpetion)\n",
        "      inception3 = Conv2D(32, (1,1), padding='same', activation='relu', bias_regularizer= l2(reg), kernel_regularizer=l2(reg))(inception3)\n",
        "\n",
        "      # 4th Arm\n",
        "      inception4 = Conv2D(64, (1,1), padding = 'same', activation = 'relu', bias_regularizer= l2(reg), kernel_regularizer=l2(reg))(input_incpetion)\n",
        "\n",
        "      # Concatenated output\n",
        "      output_inception = tf.keras.layers.concatenate([inception1, inception2, inception3, inception4], axis = 3)\n",
        "\n",
        "      return(output_inception)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7M28gAziZ_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model_inception(shape_of_input):\n",
        "    \"\"\"Generates Inception V model\n",
        "\n",
        "    :param shape_of_input: tuple with the Shape of input set\n",
        "    :return model: Inception-V1-Aux2 output\n",
        "    \"\"\"\n",
        "\n",
        "    # mish is an activation function similar to swish that improved the model accuracy when used in the dense layers\n",
        "    def mish(x):\n",
        "      return x * keras.backend.tanh(keras.backend.softplus(x))\n",
        "\n",
        "      \n",
        "    input_img = Input(shape=shape_of_input)\n",
        "    num_classes = 4 #specific to the problem in hand\n",
        "\n",
        "    layer_1 = Conv2D(64, (7,7), padding='same', strides = (2,2), activation='relu')(input_img)\n",
        "    layer_1 = MaxPooling2D((3,3), strides=(2,2), padding='same')(layer_1)\n",
        "    layer_1 = BatchNormalization()(layer_1)\n",
        "    layer_1 = Conv2D(64, (1,1), padding = 'valid', activation = 'relu', strides = (1,1))(layer_1)\n",
        "    layer_1 = Conv2D(192, (3,3), padding = 'same', activation = 'relu', strides = (1,1))(layer_1)\n",
        "    layer_1 = MaxPooling2D((3,3), strides=(2,2), padding='same')(layer_1)\n",
        "\n",
        "    output_1 = layer_1\n",
        "\n",
        "    #####\n",
        "    inception3a = inception_layer(output_1)\n",
        "    inception3b = inception_layer(inception3a)\n",
        "\n",
        "    inception4a = inception_layer(inception3b)\n",
        "    inception4b = inception_layer(inception4a)\n",
        "    inception4c = inception_layer(inception4b)\n",
        "    inception4d = inception_layer(inception4c)\n",
        "    inception4e = inception_layer(inception4d)\n",
        "\n",
        "    mid_4e = MaxPooling2D((3,3), strides=(2,2), padding='same')(inception4e)\n",
        "    mid_4e = Dropout(0.5)(mid_4e)\n",
        "\n",
        "    inception5a = inception_layer(mid_4e)\n",
        "    inception5b = inception_layer(inception5a)\n",
        "    inception5c = inception_layer(inception5b)\n",
        "    inception5_output1 = AveragePooling2D((5,5), strides = (3,3), padding = 'same')(inception5c)\n",
        "    mid_4e = Dropout(0.5)(mid_4e)\n",
        "    inception5_output1 = Conv2D(128, (1,1), strides = (1,1), activation = mish, padding = 'same')(inception5_output1)\n",
        "    \n",
        "    flat_1= Flatten()(inception5_output1)\n",
        "    dense1_output1 = Dense(512, activation= mish)(flat_1)\n",
        "    dense1_output1 = Dense(512, activation= mish)(dense1_output1)\n",
        "    dense1_output1 = Dropout(0.7)(dense1_output1)\n",
        "    output0 = Dense(num_classes, activation='softmax')(dense1_output1)\n",
        "\n",
        "    model = Model([input_img], output0)\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmVpEPW2oTn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model(model_path):\n",
        "      \"\"\"Loads model from the given path\n",
        "        :param model_path: route to the desired model\n",
        "        :return model: return the loaded model\n",
        "      \"\"\"\n",
        "      \n",
        "      def mish(x):\n",
        "        return x * keras.backend.tanh(keras.backend.softplus(x))\n",
        "\n",
        "      model= keras.models.load_model(model_path,\n",
        "                        custom_objects = {\"mish\":mish})\n",
        "\n",
        "      return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPR8YkjGnF46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_AER(X_predict):\n",
        "    \"\"\"Gives the AER prediction of the loaded model.\n",
        "      \n",
        "      :param X_predict: the instance to predict\n",
        "    \"\"\"\n",
        "    X = X_predict\n",
        "    X= X[np.newaxis, ...] # array shape (1, 130, 13, 1)\n",
        "    label_dict = {}\n",
        "    for i in range(len(mapping)):\n",
        "      label_dict.update({i:mapping[i]})\n",
        "    label_dict\n",
        "\n",
        "    # perform prediction\n",
        "    prediction = model.predict(X)\n",
        "\n",
        "    # get index with max value\n",
        "    predicted_index = np.argmax(prediction, axis=1)\n",
        "    print(\"The predicted mood is:\", label_dict[predicted_index[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUUgMrpznLre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metrics_all(model, X_test, y_test):\n",
        "    \"\"\"Provides different metrices to assess.\n",
        "\n",
        "      :param X_test: The set of instances to predict on\n",
        "      :param Y_test: Ground truth labels\n",
        "    \"\"\"\n",
        "\n",
        "    yhat_probs = model.predict(X_test, verbose=0) #class probability prediction\n",
        "    yhat_classes = np.argmax(yhat_probs, axis =1) #predicted class\n",
        "\n",
        "\n",
        "    # accuracy: (tp + tn) / (p + n)\n",
        "    accuracy = accuracy_score(y_test, yhat_classes)\n",
        "    print('Accuracy: %f' % accuracy)\n",
        "\n",
        "    # precision tp / (tp + fp)\n",
        "    precision = precision_score(y_test, yhat_classes, average='weighted')\n",
        "    print('Precision: %f' % precision)\n",
        "\n",
        "    # recall: tp / (tp + fn)\n",
        "    recall = recall_score(y_test, yhat_classes, average='weighted')\n",
        "    print('Recall: %f' % recall)\n",
        "\n",
        "    # f1: 2 tp / (2 tp + fp + fn)\n",
        "    f1 = f1_score(y_test, yhat_classes, average='weighted')\n",
        "    print('F1 score: %f' % f1)\n",
        "\n",
        "    # Confusion matrix\n",
        "    matrix = confusion_matrix(y_test, yhat_classes)\n",
        "    print(\"\\nThe confusion matrix is as below:\")\n",
        "    print(matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmrrI8CEnS-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy_per_class(preds, labels):\n",
        "    \"\"\"\n",
        "    Provides the accuracy for each class in the AER task\n",
        "\n",
        "    :param preds: Predicted labels\n",
        "    :param labels: Ground truth labels\n",
        "    \"\"\"\n",
        "\n",
        "    label_dict = {} #dictionary to map the encoded labels to their semantic labels\n",
        "    for i in range(len(mapping)):\n",
        "      label_dict.update({i:mapping[i]})\n",
        "      \n",
        "    for label in np.unique(y_test):\n",
        "        y_preds = yhat_classes[y_test==label]\n",
        "        y_true = y_test[y_test==label]\n",
        "        print(f'Class: {label_dict[label]}')\n",
        "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}')\n",
        "        print(f'Accuracy (Percentage): ', (len(y_preds[y_preds==label])/len(y_true))*100, \"%\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9WosuKBnUqg",
        "colab_type": "text"
      },
      "source": [
        "# Load and Split dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6Npkp0VJZrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get train, validation, test splits\n",
        "JSON_PATH = \"/content/drive/My Drive/DEAM JSON/Sample rate:44100, MFCC coefficient:13, Track Duration:45, segments: 20, N0. FFT = 2048\"\n",
        "X_train, X_validation, X_test, y_train, y_validation, y_test, mapping = train_val_test(0.1, 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvikArVQlra1",
        "colab_type": "text"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXGPW5CCVET5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "12bf4634-5a98-4564-e7b1-6d50aef79ff0"
      },
      "source": [
        "# create network\n",
        "shape_of_input = (X_train.shape[1], X_train.shape[2], 1)\n",
        "model = build_model_inception(shape_of_input)\n",
        "\n",
        "checkpoint = ModelCheckpoint('/content/drive1/Models/AER/Model-best-model-accuracy-inception-v1-2nd-AUX.h5', verbose = 1, monitor='val_accuracy',save_best_only=True, mode='max')\n",
        "patience = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20)\n",
        "\n",
        "\n",
        "optimiser = tf.keras.optimizers.RMSprop(learning_rate= 0.00005)\n",
        "model.compile(optimizer=optimiser,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "plot_model(model, to_file='/content/drive1/Architecture Images/inception_2nd_aux_.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "\n",
        "# train model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=64, epochs=200, callbacks=[checkpoint,patience])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 194, 13, 1)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 97, 7, 64)    3200        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 49, 4, 64)    0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 49, 4, 64)    256         max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 49, 4, 64)    4160        batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 49, 4, 192)   110784      conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 25, 2, 192)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 25, 2, 96)    18528       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 25, 2, 16)    3088        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 25, 2, 192)   0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 25, 2, 128)   110720      conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 25, 2, 32)    12832       conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 25, 2, 32)    6176        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 25, 2, 64)    12352       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 25, 2, 256)   0           conv2d_4[0][0]                   \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 25, 2, 96)    24672       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 25, 2, 16)    4112        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 25, 2, 256)   0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 25, 2, 128)   110720      conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 25, 2, 32)    12832       conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 25, 2, 32)    8224        max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 25, 2, 64)    16448       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 25, 2, 256)   0           conv2d_10[0][0]                  \n",
            "                                                                 conv2d_12[0][0]                  \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 25, 2, 96)    24672       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 25, 2, 16)    4112        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 25, 2, 256)   0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 25, 2, 128)   110720      conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 25, 2, 32)    12832       conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 25, 2, 32)    8224        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 25, 2, 64)    16448       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 25, 2, 256)   0           conv2d_16[0][0]                  \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 25, 2, 96)    24672       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 25, 2, 16)    4112        concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 25, 2, 256)   0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 25, 2, 128)   110720      conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 25, 2, 32)    12832       conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 25, 2, 32)    8224        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 25, 2, 64)    16448       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 25, 2, 256)   0           conv2d_22[0][0]                  \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "                                                                 conv2d_25[0][0]                  \n",
            "                                                                 conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 25, 2, 96)    24672       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 25, 2, 16)    4112        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 25, 2, 256)   0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 25, 2, 128)   110720      conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 25, 2, 32)    12832       conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 25, 2, 32)    8224        max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 25, 2, 64)    16448       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 25, 2, 256)   0           conv2d_28[0][0]                  \n",
            "                                                                 conv2d_30[0][0]                  \n",
            "                                                                 conv2d_31[0][0]                  \n",
            "                                                                 conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 25, 2, 96)    24672       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 25, 2, 16)    4112        concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 25, 2, 256)   0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 25, 2, 128)   110720      conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 25, 2, 32)    12832       conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 25, 2, 32)    8224        max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 25, 2, 64)    16448       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 25, 2, 256)   0           conv2d_34[0][0]                  \n",
            "                                                                 conv2d_36[0][0]                  \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "                                                                 conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 25, 2, 96)    24672       concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 25, 2, 16)    4112        concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 25, 2, 256)   0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 25, 2, 128)   110720      conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 25, 2, 32)    12832       conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 25, 2, 32)    8224        max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 25, 2, 64)    16448       concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 25, 2, 256)   0           conv2d_40[0][0]                  \n",
            "                                                                 conv2d_42[0][0]                  \n",
            "                                                                 conv2d_43[0][0]                  \n",
            "                                                                 conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 13, 1, 256)   0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 13, 1, 256)   0           max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 13, 1, 96)    24672       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 13, 1, 16)    4112        dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 13, 1, 256)   0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 13, 1, 128)   110720      conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 13, 1, 32)    12832       conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 13, 1, 32)    8224        max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 13, 1, 64)    16448       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 13, 1, 256)   0           conv2d_46[0][0]                  \n",
            "                                                                 conv2d_48[0][0]                  \n",
            "                                                                 conv2d_49[0][0]                  \n",
            "                                                                 conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 13, 1, 96)    24672       concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 13, 1, 16)    4112        concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 13, 1, 256)   0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 13, 1, 128)   110720      conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 13, 1, 32)    12832       conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 13, 1, 32)    8224        max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 13, 1, 64)    16448       concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 13, 1, 256)   0           conv2d_52[0][0]                  \n",
            "                                                                 conv2d_54[0][0]                  \n",
            "                                                                 conv2d_55[0][0]                  \n",
            "                                                                 conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 13, 1, 96)    24672       concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 13, 1, 16)    4112        concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling2D) (None, 13, 1, 256)   0           concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 13, 1, 128)   110720      conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 13, 1, 32)    12832       conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 13, 1, 32)    8224        max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 13, 1, 64)    16448       concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 13, 1, 256)   0           conv2d_58[0][0]                  \n",
            "                                                                 conv2d_60[0][0]                  \n",
            "                                                                 conv2d_61[0][0]                  \n",
            "                                                                 conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 5, 1, 256)    0           concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 5, 1, 128)    32896       average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 640)          0           conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          328192      flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          262656      dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 4)            2052        dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,500,964\n",
            "Trainable params: 2,500,836\n",
            "Non-trainable params: 128\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 1.0945 - accuracy: 0.5866\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.63391, saving model to /content/drive1/Models/AER/Model-best-model-accuracy-inception-v1-2nd-AUX.h5\n",
            "428/428 [==============================] - 53s 124ms/step - loss: 1.0945 - accuracy: 0.5866 - val_loss: 1.0424 - val_accuracy: 0.6339\n",
            "Epoch 2/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.9957 - accuracy: 0.6448\n",
            "Epoch 00002: val_accuracy did not improve from 0.63391\n",
            "428/428 [==============================] - 45s 106ms/step - loss: 0.9957 - accuracy: 0.6448 - val_loss: 1.0452 - val_accuracy: 0.6273\n",
            "Epoch 3/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.9713 - accuracy: 0.6516\n",
            "Epoch 00003: val_accuracy improved from 0.63391 to 0.63917, saving model to /content/drive1/Models/AER/Model-best-model-accuracy-inception-v1-2nd-AUX.h5\n",
            "428/428 [==============================] - 49s 115ms/step - loss: 0.9713 - accuracy: 0.6516 - val_loss: 0.9928 - val_accuracy: 0.6392\n",
            "Epoch 4/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.9445 - accuracy: 0.6585\n",
            "Epoch 00004: val_accuracy did not improve from 0.63917\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.9445 - accuracy: 0.6585 - val_loss: 1.0385 - val_accuracy: 0.6283\n",
            "Epoch 5/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.9312 - accuracy: 0.6617\n",
            "Epoch 00005: val_accuracy improved from 0.63917 to 0.66842, saving model to /content/drive1/Models/AER/Model-best-model-accuracy-inception-v1-2nd-AUX.h5\n",
            "428/428 [==============================] - 49s 115ms/step - loss: 0.9312 - accuracy: 0.6617 - val_loss: 0.9959 - val_accuracy: 0.6684\n",
            "Epoch 6/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.9099 - accuracy: 0.6685\n",
            "Epoch 00006: val_accuracy improved from 0.66842 to 0.67006, saving model to /content/drive1/Models/AER/Model-best-model-accuracy-inception-v1-2nd-AUX.h5\n",
            "428/428 [==============================] - 48s 112ms/step - loss: 0.9099 - accuracy: 0.6685 - val_loss: 0.9419 - val_accuracy: 0.6701\n",
            "Epoch 7/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.8907 - accuracy: 0.6786\n",
            "Epoch 00007: val_accuracy improved from 0.67006 to 0.67532, saving model to /content/drive1/Models/AER/Model-best-model-accuracy-inception-v1-2nd-AUX.h5\n",
            "428/428 [==============================] - 49s 115ms/step - loss: 0.8907 - accuracy: 0.6786 - val_loss: 0.9166 - val_accuracy: 0.6753\n",
            "Epoch 8/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.8634 - accuracy: 0.6866\n",
            "Epoch 00008: val_accuracy did not improve from 0.67532\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.8634 - accuracy: 0.6866 - val_loss: 0.9525 - val_accuracy: 0.6691\n",
            "Epoch 9/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.8336 - accuracy: 0.6996\n",
            "Epoch 00009: val_accuracy improved from 0.67532 to 0.70030, saving model to /content/drive1/Models/AER/Model-best-model-accuracy-inception-v1-2nd-AUX.h5\n",
            "428/428 [==============================] - 49s 115ms/step - loss: 0.8336 - accuracy: 0.6996 - val_loss: 0.8618 - val_accuracy: 0.7003\n",
            "Epoch 10/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.8023 - accuracy: 0.7107\n",
            "Epoch 00010: val_accuracy did not improve from 0.70030\n",
            "428/428 [==============================] - 45s 106ms/step - loss: 0.8023 - accuracy: 0.7107 - val_loss: 0.8964 - val_accuracy: 0.6865\n",
            "Epoch 11/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.7787 - accuracy: 0.7205\n",
            "Epoch 00011: val_accuracy improved from 0.70030 to 0.70621, saving model to /content/drive1/Models/AER/Model-best-model-accuracy-inception-v1-2nd-AUX.h5\n",
            "428/428 [==============================] - 48s 113ms/step - loss: 0.7787 - accuracy: 0.7205 - val_loss: 0.8201 - val_accuracy: 0.7062\n",
            "Epoch 12/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.7457 - accuracy: 0.7329\n",
            "Epoch 00012: val_accuracy did not improve from 0.70621\n",
            "428/428 [==============================] - 46s 108ms/step - loss: 0.7457 - accuracy: 0.7329 - val_loss: 0.9246 - val_accuracy: 0.6628\n",
            "Epoch 13/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.7198 - accuracy: 0.7420\n",
            "Epoch 00013: val_accuracy improved from 0.70621 to 0.73743, saving model to /content/drive1/Models/AER/Model-best-model-accuracy-inception-v1-2nd-AUX.h5\n",
            "428/428 [==============================] - 50s 117ms/step - loss: 0.7198 - accuracy: 0.7420 - val_loss: 0.7630 - val_accuracy: 0.7374\n",
            "Epoch 14/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.6880 - accuracy: 0.7571\n",
            "Epoch 00014: val_accuracy did not improve from 0.73743\n",
            "428/428 [==============================] - 46s 108ms/step - loss: 0.6880 - accuracy: 0.7571 - val_loss: 0.7930 - val_accuracy: 0.7151\n",
            "Epoch 15/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.6615 - accuracy: 0.7678\n",
            "Epoch 00015: val_accuracy did not improve from 0.73743\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.6615 - accuracy: 0.7678 - val_loss: 0.7744 - val_accuracy: 0.7249\n",
            "Epoch 16/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.6320 - accuracy: 0.7782\n",
            "Epoch 00016: val_accuracy did not improve from 0.73743\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.6320 - accuracy: 0.7782 - val_loss: 0.7796 - val_accuracy: 0.7243\n",
            "Epoch 17/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.6179 - accuracy: 0.7831\n",
            "Epoch 00017: val_accuracy improved from 0.73743 to 0.75419, saving model to /content/drive1/Models/AER/Model-best-model-accuracy-inception-v1-2nd-AUX.h5\n",
            "428/428 [==============================] - 49s 115ms/step - loss: 0.6179 - accuracy: 0.7831 - val_loss: 0.7211 - val_accuracy: 0.7542\n",
            "Epoch 18/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.5916 - accuracy: 0.7933\n",
            "Epoch 00018: val_accuracy did not improve from 0.75419\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.5916 - accuracy: 0.7933 - val_loss: 0.8298 - val_accuracy: 0.6872\n",
            "Epoch 19/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.5720 - accuracy: 0.8015\n",
            "Epoch 00019: val_accuracy improved from 0.75419 to 0.79100, saving model to /content/drive1/Models/AER/Model-best-model-accuracy-inception-v1-2nd-AUX.h5\n",
            "428/428 [==============================] - 49s 114ms/step - loss: 0.5720 - accuracy: 0.8015 - val_loss: 0.6375 - val_accuracy: 0.7910\n",
            "Epoch 20/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.5473 - accuracy: 0.8127\n",
            "Epoch 00020: val_accuracy did not improve from 0.79100\n",
            "428/428 [==============================] - 46s 108ms/step - loss: 0.5473 - accuracy: 0.8127 - val_loss: 0.6207 - val_accuracy: 0.7894\n",
            "Epoch 21/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.5312 - accuracy: 0.8181\n",
            "Epoch 00021: val_accuracy did not improve from 0.79100\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.5312 - accuracy: 0.8181 - val_loss: 0.6242 - val_accuracy: 0.7808\n",
            "Epoch 22/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.5003 - accuracy: 0.8308\n",
            "Epoch 00022: val_accuracy did not improve from 0.79100\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.5003 - accuracy: 0.8308 - val_loss: 0.6088 - val_accuracy: 0.7894\n",
            "Epoch 23/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.4920 - accuracy: 0.8355\n",
            "Epoch 00023: val_accuracy did not improve from 0.79100\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.4920 - accuracy: 0.8355 - val_loss: 0.6090 - val_accuracy: 0.7907\n",
            "Epoch 24/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.4657 - accuracy: 0.8463\n",
            "Epoch 00024: val_accuracy did not improve from 0.79100\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.4657 - accuracy: 0.8463 - val_loss: 0.6411 - val_accuracy: 0.7818\n",
            "Epoch 25/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.4517 - accuracy: 0.8509\n",
            "Epoch 00025: val_accuracy improved from 0.79100 to 0.80085, saving model to /content/drive1/Models/AER/Model-best-model-accuracy-inception-v1-2nd-AUX.h5\n",
            "428/428 [==============================] - 50s 117ms/step - loss: 0.4517 - accuracy: 0.8509 - val_loss: 0.5890 - val_accuracy: 0.8009\n",
            "Epoch 26/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.4308 - accuracy: 0.8577\n",
            "Epoch 00026: val_accuracy improved from 0.80085 to 0.80546, saving model to /content/drive1/Models/AER/Model-best-model-accuracy-inception-v1-2nd-AUX.h5\n",
            "428/428 [==============================] - 48s 113ms/step - loss: 0.4308 - accuracy: 0.8577 - val_loss: 0.5753 - val_accuracy: 0.8055\n",
            "Epoch 27/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.4169 - accuracy: 0.8614\n",
            "Epoch 00027: val_accuracy did not improve from 0.80546\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.4169 - accuracy: 0.8614 - val_loss: 0.6474 - val_accuracy: 0.7700\n",
            "Epoch 28/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.3973 - accuracy: 0.8695\n",
            "Epoch 00028: val_accuracy did not improve from 0.80546\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.3973 - accuracy: 0.8695 - val_loss: 0.6364 - val_accuracy: 0.7884\n",
            "Epoch 29/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.3805 - accuracy: 0.8786\n",
            "Epoch 00029: val_accuracy improved from 0.80546 to 0.81794, saving model to /content/drive1/Models/AER/Model-best-model-accuracy-inception-v1-2nd-AUX.h5\n",
            "428/428 [==============================] - 51s 118ms/step - loss: 0.3805 - accuracy: 0.8786 - val_loss: 0.5599 - val_accuracy: 0.8179\n",
            "Epoch 30/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.3744 - accuracy: 0.8793\n",
            "Epoch 00030: val_accuracy did not improve from 0.81794\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.3744 - accuracy: 0.8793 - val_loss: 0.5892 - val_accuracy: 0.8055\n",
            "Epoch 31/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.3521 - accuracy: 0.8890\n",
            "Epoch 00031: val_accuracy did not improve from 0.81794\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.3521 - accuracy: 0.8890 - val_loss: 0.5967 - val_accuracy: 0.8081\n",
            "Epoch 32/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.3436 - accuracy: 0.8902\n",
            "Epoch 00032: val_accuracy did not improve from 0.81794\n",
            "428/428 [==============================] - 46s 108ms/step - loss: 0.3436 - accuracy: 0.8902 - val_loss: 0.6230 - val_accuracy: 0.8051\n",
            "Epoch 33/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.3313 - accuracy: 0.8952\n",
            "Epoch 00033: val_accuracy did not improve from 0.81794\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.3313 - accuracy: 0.8952 - val_loss: 0.5558 - val_accuracy: 0.8173\n",
            "Epoch 34/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.3160 - accuracy: 0.9011\n",
            "Epoch 00034: val_accuracy did not improve from 0.81794\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.3160 - accuracy: 0.9011 - val_loss: 0.6054 - val_accuracy: 0.7999\n",
            "Epoch 35/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.3025 - accuracy: 0.9062\n",
            "Epoch 00035: val_accuracy did not improve from 0.81794\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.3025 - accuracy: 0.9062 - val_loss: 0.6212 - val_accuracy: 0.7930\n",
            "Epoch 36/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.2887 - accuracy: 0.9111\n",
            "Epoch 00036: val_accuracy did not improve from 0.81794\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.2887 - accuracy: 0.9111 - val_loss: 0.6012 - val_accuracy: 0.7946\n",
            "Epoch 37/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.2816 - accuracy: 0.9133\n",
            "Epoch 00037: val_accuracy did not improve from 0.81794\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.2816 - accuracy: 0.9133 - val_loss: 0.5905 - val_accuracy: 0.8051\n",
            "Epoch 38/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.2709 - accuracy: 0.9199\n",
            "Epoch 00038: val_accuracy did not improve from 0.81794\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.2709 - accuracy: 0.9199 - val_loss: 0.5851 - val_accuracy: 0.8012\n",
            "Epoch 39/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.2656 - accuracy: 0.9204\n",
            "Epoch 00039: val_accuracy improved from 0.81794 to 0.82583, saving model to /content/drive1/Models/AER/Model-best-model-accuracy-inception-v1-2nd-AUX.h5\n",
            "428/428 [==============================] - 50s 117ms/step - loss: 0.2656 - accuracy: 0.9204 - val_loss: 0.5425 - val_accuracy: 0.8258\n",
            "Epoch 40/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.2553 - accuracy: 0.9237\n",
            "Epoch 00040: val_accuracy improved from 0.82583 to 0.84160, saving model to /content/drive1/Models/AER/Model-best-model-accuracy-inception-v1-2nd-AUX.h5\n",
            "428/428 [==============================] - 49s 113ms/step - loss: 0.2553 - accuracy: 0.9237 - val_loss: 0.5050 - val_accuracy: 0.8416\n",
            "Epoch 41/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.2363 - accuracy: 0.9323\n",
            "Epoch 00041: val_accuracy did not improve from 0.84160\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.2363 - accuracy: 0.9323 - val_loss: 0.5585 - val_accuracy: 0.8275\n",
            "Epoch 42/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.2274 - accuracy: 0.9328\n",
            "Epoch 00042: val_accuracy did not improve from 0.84160\n",
            "428/428 [==============================] - 45s 106ms/step - loss: 0.2274 - accuracy: 0.9328 - val_loss: 0.6947 - val_accuracy: 0.8071\n",
            "Epoch 43/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.2244 - accuracy: 0.9349\n",
            "Epoch 00043: val_accuracy did not improve from 0.84160\n",
            "428/428 [==============================] - 45s 106ms/step - loss: 0.2244 - accuracy: 0.9349 - val_loss: 0.5763 - val_accuracy: 0.8143\n",
            "Epoch 44/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.2185 - accuracy: 0.9353\n",
            "Epoch 00044: val_accuracy did not improve from 0.84160\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.2185 - accuracy: 0.9353 - val_loss: 0.9309 - val_accuracy: 0.7506\n",
            "Epoch 45/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.2119 - accuracy: 0.9384\n",
            "Epoch 00045: val_accuracy did not improve from 0.84160\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.2119 - accuracy: 0.9384 - val_loss: 0.5448 - val_accuracy: 0.8363\n",
            "Epoch 46/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.2011 - accuracy: 0.9419\n",
            "Epoch 00046: val_accuracy did not improve from 0.84160\n",
            "428/428 [==============================] - 45s 106ms/step - loss: 0.2011 - accuracy: 0.9419 - val_loss: 0.5628 - val_accuracy: 0.8294\n",
            "Epoch 47/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.2005 - accuracy: 0.9446\n",
            "Epoch 00047: val_accuracy did not improve from 0.84160\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.2005 - accuracy: 0.9446 - val_loss: 0.5787 - val_accuracy: 0.8248\n",
            "Epoch 48/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1936 - accuracy: 0.9458\n",
            "Epoch 00048: val_accuracy did not improve from 0.84160\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.1936 - accuracy: 0.9458 - val_loss: 0.9749 - val_accuracy: 0.7269\n",
            "Epoch 49/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1862 - accuracy: 0.9492\n",
            "Epoch 00049: val_accuracy did not improve from 0.84160\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.1862 - accuracy: 0.9492 - val_loss: 0.5529 - val_accuracy: 0.8383\n",
            "Epoch 50/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1783 - accuracy: 0.9523\n",
            "Epoch 00050: val_accuracy did not improve from 0.84160\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.1783 - accuracy: 0.9523 - val_loss: 0.7502 - val_accuracy: 0.8107\n",
            "Epoch 51/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1789 - accuracy: 0.9521\n",
            "Epoch 00051: val_accuracy did not improve from 0.84160\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.1789 - accuracy: 0.9521 - val_loss: 0.5332 - val_accuracy: 0.8403\n",
            "Epoch 52/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1736 - accuracy: 0.9548\n",
            "Epoch 00052: val_accuracy did not improve from 0.84160\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.1736 - accuracy: 0.9548 - val_loss: 0.7182 - val_accuracy: 0.8002\n",
            "Epoch 53/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1733 - accuracy: 0.9532\n",
            "Epoch 00053: val_accuracy did not improve from 0.84160\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.1733 - accuracy: 0.9532 - val_loss: 0.5542 - val_accuracy: 0.8334\n",
            "Epoch 54/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1640 - accuracy: 0.9573\n",
            "Epoch 00054: val_accuracy did not improve from 0.84160\n",
            "428/428 [==============================] - 46s 106ms/step - loss: 0.1640 - accuracy: 0.9573 - val_loss: 0.6866 - val_accuracy: 0.8120\n",
            "Epoch 55/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1557 - accuracy: 0.9601\n",
            "Epoch 00055: val_accuracy did not improve from 0.84160\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.1557 - accuracy: 0.9601 - val_loss: 0.6608 - val_accuracy: 0.8275\n",
            "Epoch 56/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1525 - accuracy: 0.9604\n",
            "Epoch 00056: val_accuracy did not improve from 0.84160\n",
            "428/428 [==============================] - 46s 107ms/step - loss: 0.1525 - accuracy: 0.9604 - val_loss: 0.5475 - val_accuracy: 0.8363\n",
            "Epoch 57/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1523 - accuracy: 0.9610\n",
            "Epoch 00057: val_accuracy improved from 0.84160 to 0.84850, saving model to /content/drive1/Models/AER/Model-best-model-accuracy-inception-v1-2nd-AUX.h5\n",
            "428/428 [==============================] - 48s 113ms/step - loss: 0.1523 - accuracy: 0.9610 - val_loss: 0.5327 - val_accuracy: 0.8485\n",
            "Epoch 58/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1536 - accuracy: 0.9620\n",
            "Epoch 00058: val_accuracy did not improve from 0.84850\n",
            "428/428 [==============================] - 45s 106ms/step - loss: 0.1536 - accuracy: 0.9620 - val_loss: 0.5486 - val_accuracy: 0.8409\n",
            "Epoch 59/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 0.9636\n",
            "Epoch 00059: val_accuracy did not improve from 0.84850\n",
            "428/428 [==============================] - 45s 106ms/step - loss: 0.1423 - accuracy: 0.9636 - val_loss: 0.8810 - val_accuracy: 0.8012\n",
            "Epoch 60/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1432 - accuracy: 0.9645\n",
            "Epoch 00060: val_accuracy improved from 0.84850 to 0.85015, saving model to /content/drive1/Models/AER/Model-best-model-accuracy-inception-v1-2nd-AUX.h5\n",
            "428/428 [==============================] - 48s 112ms/step - loss: 0.1432 - accuracy: 0.9645 - val_loss: 0.5334 - val_accuracy: 0.8501\n",
            "Epoch 61/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1395 - accuracy: 0.9652\n",
            "Epoch 00061: val_accuracy did not improve from 0.85015\n",
            "428/428 [==============================] - 45s 106ms/step - loss: 0.1395 - accuracy: 0.9652 - val_loss: 0.5696 - val_accuracy: 0.8478\n",
            "Epoch 62/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1377 - accuracy: 0.9666\n",
            "Epoch 00062: val_accuracy did not improve from 0.85015\n",
            "428/428 [==============================] - 45s 105ms/step - loss: 0.1377 - accuracy: 0.9666 - val_loss: 0.5794 - val_accuracy: 0.8475\n",
            "Epoch 63/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1298 - accuracy: 0.9675\n",
            "Epoch 00063: val_accuracy did not improve from 0.85015\n",
            "428/428 [==============================] - 45s 105ms/step - loss: 0.1298 - accuracy: 0.9675 - val_loss: 0.5829 - val_accuracy: 0.8363\n",
            "Epoch 64/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1336 - accuracy: 0.9686\n",
            "Epoch 00064: val_accuracy did not improve from 0.85015\n",
            "428/428 [==============================] - 45s 105ms/step - loss: 0.1336 - accuracy: 0.9686 - val_loss: 0.5578 - val_accuracy: 0.8478\n",
            "Epoch 65/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1305 - accuracy: 0.9687\n",
            "Epoch 00065: val_accuracy did not improve from 0.85015\n",
            "428/428 [==============================] - 45s 106ms/step - loss: 0.1305 - accuracy: 0.9687 - val_loss: 0.6671 - val_accuracy: 0.8166\n",
            "Epoch 66/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1297 - accuracy: 0.9691\n",
            "Epoch 00066: val_accuracy did not improve from 0.85015\n",
            "428/428 [==============================] - 45s 106ms/step - loss: 0.1297 - accuracy: 0.9691 - val_loss: 0.5482 - val_accuracy: 0.8478\n",
            "Epoch 67/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1278 - accuracy: 0.9698\n",
            "Epoch 00067: val_accuracy did not improve from 0.85015\n",
            "428/428 [==============================] - 45s 106ms/step - loss: 0.1278 - accuracy: 0.9698 - val_loss: 0.6177 - val_accuracy: 0.8413\n",
            "Epoch 68/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1207 - accuracy: 0.9707\n",
            "Epoch 00068: val_accuracy improved from 0.85015 to 0.85968, saving model to /content/drive1/Models/AER/Model-best-model-accuracy-inception-v1-2nd-AUX.h5\n",
            "428/428 [==============================] - 48s 111ms/step - loss: 0.1207 - accuracy: 0.9707 - val_loss: 0.5720 - val_accuracy: 0.8597\n",
            "Epoch 69/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1265 - accuracy: 0.9708\n",
            "Epoch 00069: val_accuracy did not improve from 0.85968\n",
            "428/428 [==============================] - 45s 106ms/step - loss: 0.1265 - accuracy: 0.9708 - val_loss: 0.6694 - val_accuracy: 0.8278\n",
            "Epoch 70/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1143 - accuracy: 0.9750\n",
            "Epoch 00070: val_accuracy did not improve from 0.85968\n",
            "428/428 [==============================] - 45s 106ms/step - loss: 0.1143 - accuracy: 0.9750 - val_loss: 0.5472 - val_accuracy: 0.8587\n",
            "Epoch 71/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1199 - accuracy: 0.9720\n",
            "Epoch 00071: val_accuracy did not improve from 0.85968\n",
            "428/428 [==============================] - 45s 106ms/step - loss: 0.1199 - accuracy: 0.9720 - val_loss: 0.5729 - val_accuracy: 0.8426\n",
            "Epoch 72/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1165 - accuracy: 0.9736\n",
            "Epoch 00072: val_accuracy did not improve from 0.85968\n",
            "428/428 [==============================] - 45s 105ms/step - loss: 0.1165 - accuracy: 0.9736 - val_loss: 0.6148 - val_accuracy: 0.8281\n",
            "Epoch 73/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1147 - accuracy: 0.9746\n",
            "Epoch 00073: val_accuracy did not improve from 0.85968\n",
            "428/428 [==============================] - 45s 106ms/step - loss: 0.1147 - accuracy: 0.9746 - val_loss: 0.6975 - val_accuracy: 0.8354\n",
            "Epoch 74/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 0.9754\n",
            "Epoch 00074: val_accuracy did not improve from 0.85968\n",
            "428/428 [==============================] - 45s 105ms/step - loss: 0.1127 - accuracy: 0.9754 - val_loss: 0.5674 - val_accuracy: 0.8472\n",
            "Epoch 75/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1096 - accuracy: 0.9753\n",
            "Epoch 00075: val_accuracy did not improve from 0.85968\n",
            "428/428 [==============================] - 45s 105ms/step - loss: 0.1096 - accuracy: 0.9753 - val_loss: 0.6431 - val_accuracy: 0.8482\n",
            "Epoch 76/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1105 - accuracy: 0.9757\n",
            "Epoch 00076: val_accuracy did not improve from 0.85968\n",
            "428/428 [==============================] - 45s 106ms/step - loss: 0.1105 - accuracy: 0.9757 - val_loss: 0.5514 - val_accuracy: 0.8482\n",
            "Epoch 77/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1058 - accuracy: 0.9765\n",
            "Epoch 00077: val_accuracy did not improve from 0.85968\n",
            "428/428 [==============================] - 45s 106ms/step - loss: 0.1058 - accuracy: 0.9765 - val_loss: 0.6140 - val_accuracy: 0.8429\n",
            "Epoch 78/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1131 - accuracy: 0.9755\n",
            "Epoch 00078: val_accuracy did not improve from 0.85968\n",
            "428/428 [==============================] - 45s 105ms/step - loss: 0.1131 - accuracy: 0.9755 - val_loss: 0.5420 - val_accuracy: 0.8541\n",
            "Epoch 79/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1011 - accuracy: 0.9785\n",
            "Epoch 00079: val_accuracy did not improve from 0.85968\n",
            "428/428 [==============================] - 45s 105ms/step - loss: 0.1011 - accuracy: 0.9785 - val_loss: 0.5785 - val_accuracy: 0.8508\n",
            "Epoch 80/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1023 - accuracy: 0.9779\n",
            "Epoch 00080: val_accuracy did not improve from 0.85968\n",
            "428/428 [==============================] - 45s 105ms/step - loss: 0.1023 - accuracy: 0.9779 - val_loss: 0.6399 - val_accuracy: 0.8380\n",
            "Epoch 81/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.9788\n",
            "Epoch 00081: val_accuracy did not improve from 0.85968\n",
            "428/428 [==============================] - 45s 106ms/step - loss: 0.0978 - accuracy: 0.9788 - val_loss: 1.0398 - val_accuracy: 0.7765\n",
            "Epoch 82/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1009 - accuracy: 0.9786\n",
            "Epoch 00082: val_accuracy did not improve from 0.85968\n",
            "428/428 [==============================] - 45s 105ms/step - loss: 0.1009 - accuracy: 0.9786 - val_loss: 0.7567 - val_accuracy: 0.8229\n",
            "Epoch 83/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1074 - accuracy: 0.9771\n",
            "Epoch 00083: val_accuracy did not improve from 0.85968\n",
            "428/428 [==============================] - 45s 105ms/step - loss: 0.1074 - accuracy: 0.9771 - val_loss: 0.6147 - val_accuracy: 0.8469\n",
            "Epoch 84/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.0990 - accuracy: 0.9791\n",
            "Epoch 00084: val_accuracy improved from 0.85968 to 0.86001, saving model to /content/drive1/Models/AER/Model-best-model-accuracy-inception-v1-2nd-AUX.h5\n",
            "428/428 [==============================] - 48s 113ms/step - loss: 0.0990 - accuracy: 0.9791 - val_loss: 0.5909 - val_accuracy: 0.8600\n",
            "Epoch 85/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.0981 - accuracy: 0.9792\n",
            "Epoch 00085: val_accuracy did not improve from 0.86001\n",
            "428/428 [==============================] - 45s 106ms/step - loss: 0.0981 - accuracy: 0.9792 - val_loss: 0.7674 - val_accuracy: 0.8081\n",
            "Epoch 86/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.1010 - accuracy: 0.9788\n",
            "Epoch 00086: val_accuracy did not improve from 0.86001\n",
            "428/428 [==============================] - 45s 105ms/step - loss: 0.1010 - accuracy: 0.9788 - val_loss: 0.6620 - val_accuracy: 0.8357\n",
            "Epoch 87/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.0937 - accuracy: 0.9805\n",
            "Epoch 00087: val_accuracy did not improve from 0.86001\n",
            "428/428 [==============================] - 45s 106ms/step - loss: 0.0937 - accuracy: 0.9805 - val_loss: 1.0140 - val_accuracy: 0.7844\n",
            "Epoch 88/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.0977 - accuracy: 0.9804\n",
            "Epoch 00088: val_accuracy did not improve from 0.86001\n",
            "428/428 [==============================] - 45s 106ms/step - loss: 0.0977 - accuracy: 0.9804 - val_loss: 0.6382 - val_accuracy: 0.8570\n",
            "Epoch 89/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.0967 - accuracy: 0.9813\n",
            "Epoch 00089: val_accuracy did not improve from 0.86001\n",
            "428/428 [==============================] - 45s 105ms/step - loss: 0.0967 - accuracy: 0.9813 - val_loss: 0.8941 - val_accuracy: 0.7798\n",
            "Epoch 90/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.0961 - accuracy: 0.9797\n",
            "Epoch 00090: val_accuracy did not improve from 0.86001\n",
            "428/428 [==============================] - 45s 105ms/step - loss: 0.0961 - accuracy: 0.9797 - val_loss: 0.6008 - val_accuracy: 0.8511\n",
            "Epoch 91/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.0915 - accuracy: 0.9818\n",
            "Epoch 00091: val_accuracy did not improve from 0.86001\n",
            "428/428 [==============================] - 45s 105ms/step - loss: 0.0915 - accuracy: 0.9818 - val_loss: 0.6776 - val_accuracy: 0.8465\n",
            "Epoch 92/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.9805\n",
            "Epoch 00092: val_accuracy did not improve from 0.86001\n",
            "428/428 [==============================] - 45s 105ms/step - loss: 0.0954 - accuracy: 0.9805 - val_loss: 0.5615 - val_accuracy: 0.8544\n",
            "Epoch 93/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.0937 - accuracy: 0.9813\n",
            "Epoch 00093: val_accuracy did not improve from 0.86001\n",
            "428/428 [==============================] - 45s 105ms/step - loss: 0.0937 - accuracy: 0.9813 - val_loss: 0.6353 - val_accuracy: 0.8380\n",
            "Epoch 94/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.0895 - accuracy: 0.9835\n",
            "Epoch 00094: val_accuracy did not improve from 0.86001\n",
            "428/428 [==============================] - 45s 105ms/step - loss: 0.0895 - accuracy: 0.9835 - val_loss: 0.6571 - val_accuracy: 0.8492\n",
            "Epoch 95/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.0932 - accuracy: 0.9824\n",
            "Epoch 00095: val_accuracy did not improve from 0.86001\n",
            "428/428 [==============================] - 45s 105ms/step - loss: 0.0932 - accuracy: 0.9824 - val_loss: 0.6178 - val_accuracy: 0.8534\n",
            "Epoch 96/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.0831 - accuracy: 0.9837\n",
            "Epoch 00096: val_accuracy did not improve from 0.86001\n",
            "428/428 [==============================] - 45s 105ms/step - loss: 0.0831 - accuracy: 0.9837 - val_loss: 0.5552 - val_accuracy: 0.8557\n",
            "Epoch 97/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.0891 - accuracy: 0.9830\n",
            "Epoch 00097: val_accuracy did not improve from 0.86001\n",
            "428/428 [==============================] - 45s 105ms/step - loss: 0.0891 - accuracy: 0.9830 - val_loss: 0.7531 - val_accuracy: 0.8275\n",
            "Epoch 98/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.9836\n",
            "Epoch 00098: val_accuracy did not improve from 0.86001\n",
            "428/428 [==============================] - 45s 105ms/step - loss: 0.0847 - accuracy: 0.9836 - val_loss: 0.7656 - val_accuracy: 0.8120\n",
            "Epoch 99/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 0.9833\n",
            "Epoch 00099: val_accuracy did not improve from 0.86001\n",
            "428/428 [==============================] - 45s 106ms/step - loss: 0.0841 - accuracy: 0.9833 - val_loss: 0.7385 - val_accuracy: 0.8170\n",
            "Epoch 100/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.9836\n",
            "Epoch 00100: val_accuracy did not improve from 0.86001\n",
            "428/428 [==============================] - 45s 106ms/step - loss: 0.0838 - accuracy: 0.9836 - val_loss: 0.5984 - val_accuracy: 0.8475\n",
            "Epoch 101/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.0872 - accuracy: 0.9824\n",
            "Epoch 00101: val_accuracy did not improve from 0.86001\n",
            "428/428 [==============================] - 45s 105ms/step - loss: 0.0872 - accuracy: 0.9824 - val_loss: 0.6419 - val_accuracy: 0.8567\n",
            "Epoch 102/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9829\n",
            "Epoch 00102: val_accuracy did not improve from 0.86001\n",
            "428/428 [==============================] - 45s 105ms/step - loss: 0.0860 - accuracy: 0.9829 - val_loss: 0.6068 - val_accuracy: 0.8521\n",
            "Epoch 103/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.0807 - accuracy: 0.9846\n",
            "Epoch 00103: val_accuracy did not improve from 0.86001\n",
            "428/428 [==============================] - 45s 105ms/step - loss: 0.0807 - accuracy: 0.9846 - val_loss: 1.0710 - val_accuracy: 0.7785\n",
            "Epoch 104/200\n",
            "428/428 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9831\n",
            "Epoch 00104: val_accuracy did not improve from 0.86001\n",
            "428/428 [==============================] - 45s 105ms/step - loss: 0.0873 - accuracy: 0.9831 - val_loss: 0.6407 - val_accuracy: 0.8429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3_KT4CGlonQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Plots and Predictions (The Fun Part)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yu7sEiqaNnT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "737bc5f8-6aa8-40f1-89cd-236d75471318"
      },
      "source": [
        "viz_history(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJyd1XWkRPvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model(\"/content/drive1/Models/AER/Model-best-model-accuracy-inception-v1-2nd-AUX.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzB3Ed1QOEaM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "abf8c375-bacf-4c34-8751-881eb4511c62"
      },
      "source": [
        "predict_AER(X_test[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The predicted mood is: Happy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ithM882Okyw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "1bfa08af-3043-4b43-8dc5-957291297701"
      },
      "source": [
        "metrics_all(model,X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.854820\n",
            "Precision: 0.853990\n",
            "Recall: 0.854820\n",
            "F1 score: 0.852720\n",
            "\n",
            "The confusion matrix is as below:\n",
            "[[1049   86   28   19]\n",
            " [  60 1256   17   39]\n",
            " [  46   61  288   11]\n",
            " [  44   73    7  298]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-3wCdhwQa98",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "74b8900a-6529-4d34-b5aa-2b252d68a1ad"
      },
      "source": [
        "yhat_probs = model.predict(X_test, verbose=0)\n",
        "yhat_classes = np.argmax(yhat_probs, axis =1)\n",
        "\n",
        "accuracy_per_class (yhat_classes, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: Happy\n",
            "Accuracy: 1049/1182\n",
            "Accuracy (Percentage):  88.74788494077835 %\n",
            "\n",
            "Class: Sad\n",
            "Accuracy: 1256/1372\n",
            "Accuracy (Percentage):  91.54518950437318 %\n",
            "\n",
            "Class: Angry\n",
            "Accuracy: 288/406\n",
            "Accuracy (Percentage):  70.93596059113301 %\n",
            "\n",
            "Class: Relaxed\n",
            "Accuracy: 298/422\n",
            "Accuracy (Percentage):  70.61611374407583 %\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}